# 数据爬取
- 题目给我爬虫脚本文件只能爬取在排行榜中前10番剧的评论，这样得到的评论一般都是给分比较高的。高分评论过多，这样就会在数据层面产生偏见，模型对于低分评价的泛化能力就会降低。
- 所以我大量修改了爬虫脚本，使其可以分别在高、中、低三个分段中，随机选择番剧，然后再爬取评论。这样可以使得评分尽可能的分散在整个区间中。
- 三个分段的评论、评分，各自生成一个数据集，然后合并，并绘制频率分布图。并与原本爬虫脚本生成的数据集，生成的频率分布图进行比较。可以看到，新的数据集在3-7分的分段多了很多样本，有助于模型学习中低分段的评论，增强泛化能力。

原本的爬虫文件爬取数据集的评分频率分布
![原本的爬虫文件爬取数据集的评分频率分布](https://hysinoss-1334037784.cos.ap-shanghai.myqcloud.com/test/single_rating_distribution.png)

修改后爬虫脚本获取的数据集评分频率分布
![修改后爬虫脚本获取的数据集评分频率分布](https://hysinoss-1334037784.cos.ap-shanghai.myqcloud.com/test/rating_distribution.png)
# 数据清洗
#### **清洗评论文本**
- **问题**：评论可能包含无关字符、重复内容或格式问题。
- **去除特殊字符和多余空格**：例如标点符号、换行符、表情符号（视情况保留有意义的表情）。
#### **处理不平衡数据（可选）**
- **问题**：评分分布可能不均匀（例如大部分是8-10分，少量低分）。
- **操作**：考虑下采样高频评分或上采样低频评分（例如用SMOTE）。
- **我打算分别尝试处理、与不处理，这两者训练出来的模型哪一个效果更好一些**
#### **数据去重**
- **问题**：重复的评论和评分对可能影响模型泛化能力。
- **操作**：删除完全相同的评论-评分对。
#### 使用LLM批处理进行数据清洗（可选）
- **我将分别尝试使用传统方法，或者使用LLM进行数据清洗，并对比训练结果**

# 数据预处理
####  **文本分词与Tokenization**
- **工具**：使用`transformers`库中与`bert-base-chinese`配套的`BertTokenizer`。
- **注意**：
    - 中文BERT使用字级别分词（而不是词级别），无需额外分词工具（如jieba）。
    - 输入长度有限（最大512个token），长评论需要截断。
#### **标签处理**
- 将评分（1-10）归一化到[0, 1]，便于模型输出。
#### 划分数据集
- 按8:1:1划分训练集、验证集和测试集
- 确保评分分布在各子集间尽量一致（分层抽样）。


# 模型微调
对预训练的中⽂BERT模型（模型ID为google-bert/bert-basechinese）进⾏微调训练，请你使⽤pytorch编写训练脚本。
### 任务头设计
- 在BERT输出（`[CLS]` token的表示）后加一个线性层，输出单一值。
- 损失函数用均方误差（MSE）。
### 超参数设计
- 由于是回归任务，学习率用`2e-5`、`3e-5`或`5e-5`。
- Batch size：根据GPU显存选择4、8、16。
- epochs：5轮
### 正则化
- 避免过拟合
- 默认的权重衰减（weight decay）设为0.01。
- 数据量小，可用Dropout
### 早停
- 避免过拟合
### 评估指标
- **回归任务**：用MSE、MAE或Spearman相关系数。
- 关注低频评分（1-3分）的预测效果，避免模型“偏科”。
### 保存模型