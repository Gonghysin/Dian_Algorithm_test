# 一、随机森林的理解与实现

使⽤numpy从头实现⼀个随机森林算法，拟合数据集
对提供的特征的重要性进⾏评估并可视化

## 1. 数据集划分

每个特征分别划分，取0.7做训练集，0.3做测试集
这种划分在小数据集上较为常见。
打乱数据后再按类别划分

## 2. 构建随机森林模型

### 选择CART决策树
- **处理连续特征**：能直接处理 Iris 数据集的 4 个连续特征，无需额外预处理。
- **分类任务支持**：使用基尼指数，支持多分类，适用于 3 个类别的分类问题。
- **随机森林兼容性**：CART 是随机森林中最常用的决策树算法，其二叉树结构和高效性与集成学习框架高度匹配。

## 特征选择
- 在每个节点，使用基尼指数（Gini Index）作为特征选择的准则。基尼指数衡量数据的不纯度，公式为：
$$
Gini(D) = 1 - \sum_{i=1}^{3} p_i^2
$$
- 其中 $p_i$ 是当前节点中类别 $i$ 的比例（Iris 有 3 个类别）。
- **节点分裂**：
    - 对每个特征，尝试所有可能的阈值（因为特征是连续值），计算分裂后左右子节点的基尼指数加权平均，选择使基尼指数下降最多的特征和阈值进行分裂。
- **停止条件**：
    - 设置以下条件之一停止树的生长：
        - 节点样本全属于同一类别。
        - 样本数量小于某个最小值（2）。
        - 树深度达到最大值（5）。

## 随机森林构建
- **Bootstrap 采样**：
    - 从训练集（105 条记录）中有放回地随机抽取 105 条记录，生成一个子数据集。
    - 重复此过程，为每棵决策树生成一个独立的 Bootstrap 样本。
- **特征子集选择**：
    - 在每个节点分裂时，从 4 个特征中随机选择一个子集（建议选择 2 个特征）。
    - 只在选定的特征子集中寻找最优分裂点。
- **构建多棵决策树**：
    - 确定随机森林中决策树的棵数（建议 100 棵）。
    - 对每个 Bootstrap 样本，使用上述 CART 算法构建一棵决策树。
- **注意事项**：
    - 每棵树独立构建，不进行剪枝，随机森林通过集成多棵树来控制过拟合。

## 训练随机森林模型

- **训练过程**：
    - 对每个 Bootstrap 样本，使用 CART 算法训练一棵决策树。
    - 在每个节点分裂时，确保只从随机选择的特征子集中挑选最优特征和阈值。
- **模型保存**：
    - 将所有训练好的决策树（例如 100 棵）保存为一个随机森林模型，供后续预测使用。

## 实现预测方法

- **单棵树的预测**：
    - 对于测试集中的一个样本，从树的根节点开始，根据特征值和分裂条件遍历到叶节点，输出叶节点的类别（多数类别）。
- **随机森林的预测**：
    - 对测试集中的每个样本，让所有决策树（例如 100 棵）分别预测。
    - 使用**多数投票**方法确定最终类别：
        - 统计每棵树预测的类别，得票最多的类别作为随机森林的预测结果。
    - **可选**：记录每个类别的得票数，计算得票比例，作为预测的置信度。

## 实现评价函数与模型评估

- ### 选择评价指标
	- **准确率**
	- **精确率（Precision）、召回率（Recall）、F1 分数（F1-Score）**
		- 对每个类别分别计算
	- **混淆矩阵（Confusion Matrix）**：
	    - 构建一个 3x3 矩阵（因为有 3 个类别），行表示真实类别，列表示预测类别，记录每个类别的预测情况。
- ### 实现评价函数
	- **输入**：测试集的真实标签和随机森林的预测标签。
	- **步骤**：
	    1. 计算准确率：
	        - 比较预测标签和真实标签，统计正确预测的样本数，除以测试集总数（45）。
	    2. 构建混淆矩阵：
	        - 初始化一个 3x3 矩阵，遍历测试集样本，根据真实标签和预测标签填充矩阵。
	    3. 计算每个类别的精确率、召回率和 F1 分数：
	        - 从混淆矩阵中提取每个类别的真阳性（TP）、假阳性（FP）、假阴性（FN），代入公式计算。
	- **输出**：准确率、混淆矩阵、每个类别的精确率、召回率和 F1 分数。
- ### 评估模型
	- **预测**：
	    - 使用测试集（45 条记录）对随机森林进行预测，得到预测标签。
	    - **使用5折交叉验证**
	- **计算指标**：
	    - 使用你实现的评价函数，计算上述指标。
	- **分析结果**：
	    - 检查准确率是否较高（例如 >90%），表示模型整体性能良好。
	    - 查看混淆矩阵，分析是否存在某个类别预测不准确（例如，某个类别的对角线值较低）。
	    - 比较每个类别的精确率和召回率，判断模型是否对某些类别偏倚。
## 优化
- 尝试不同超参数（50，200）
- 调整最大深度（max_depth）或最小样本数（min_samples_split），看看是否能提升准确率。